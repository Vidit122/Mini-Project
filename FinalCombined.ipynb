{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNHxX30FWW8PMPZ5RAV0V2U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vidit122/Mini-Project/blob/main/FinalCombined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaapcYysvp49"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Reshape, Conv2D, DepthwiseConv2D,\n",
        "    BatchNormalization, ReLU, GlobalAveragePooling2D,\n",
        "    Bidirectional, GRU, Dense, Dropout, Concatenate\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"5G_NIDD_FULL_9CLASS_MIXED.csv\", low_memory=False)\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns[:10])\n",
        "print(df[\"Label\"].value_counts())\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns[:10])\n",
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBObGY8-vrxi",
        "outputId": "cb494eff-7cbc-45a5-becc-c80204ff3884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1693627, 51)\n",
            "Index(['Max', 'AckDat', 'DstLoss', 'dDSb', 'Sum', 'Mean', 'SrcTCPBase', 'sDSb',\n",
            "       'dTtl', 'TotBytes'],\n",
            "      dtype='object')\n",
            "Label\n",
            "Benign         477737\n",
            "UDPFlood1      467717\n",
            "UDPFlood2      286197\n",
            "Goldeneye1      93803\n",
            "Goldeneye2      93650\n",
            "SYNFlood1       44636\n",
            "Torshammer1     38120\n",
            "Torshammer2     31669\n",
            "Slowloris1      31015\n",
            "ICMPFlood1      18279\n",
            "ICMPFlood2      14452\n",
            "SYNFlood2       14108\n",
            "Slowloris2      12656\n",
            "TCPConnect2     11653\n",
            "TCPConnect1     11645\n",
            "SYNScan2        11526\n",
            "SYNScan1        11450\n",
            "UDPScan2        10305\n",
            "UDPScan1        10043\n",
            "SSH1             1608\n",
            "SSH2             1358\n",
            "Name: count, dtype: int64\n",
            "(1693627, 51)\n",
            "Index(['Max', 'AckDat', 'DstLoss', 'dDSb', 'Sum', 'Mean', 'SrcTCPBase', 'sDSb',\n",
            "       'dTtl', 'TotBytes'],\n",
            "      dtype='object')\n",
            "Label\n",
            "Benign         477737\n",
            "UDPFlood1      467717\n",
            "UDPFlood2      286197\n",
            "Goldeneye1      93803\n",
            "Goldeneye2      93650\n",
            "SYNFlood1       44636\n",
            "Torshammer1     38120\n",
            "Torshammer2     31669\n",
            "Slowloris1      31015\n",
            "ICMPFlood1      18279\n",
            "ICMPFlood2      14452\n",
            "SYNFlood2       14108\n",
            "Slowloris2      12656\n",
            "TCPConnect2     11653\n",
            "TCPConnect1     11645\n",
            "SYNScan2        11526\n",
            "SYNScan1        11450\n",
            "UDPScan2        10305\n",
            "UDPScan1        10043\n",
            "SSH1             1608\n",
            "SSH2             1358\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ALWAYS start from df\n",
        "X = df.drop(columns=[\"Label\"])\n",
        "y = df[\"Label\"]\n",
        "\n",
        "# Force numeric\n",
        "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "print(\"X shape BEFORE slicing:\", X.shape)\n",
        " # MUST be > 36 columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk81naLbvs3N",
        "outputId": "53c3dd43-7445-48b1-a3ef-cbdc5196589c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape BEFORE slicing: (1693627, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X = X.iloc[:, :36]\n",
        "# print(\"X shape AFTER slicing:\", X.shape)"
      ],
      "metadata": {
        "id": "H0uFYWjWvuQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    # HTTP floods\n",
        "    \"Goldeneye1\": \"HTTP_Flood\",\n",
        "    \"Goldeneye2\": \"HTTP_Flood\",\n",
        "    \"Torshammer1\": \"HTTP_Flood\",\n",
        "    \"Torshammer2\": \"HTTP_Flood\",\n",
        "\n",
        "    # Slow DoS\n",
        "    \"Slowloris1\": \"Slowrate_DoS\",\n",
        "    \"Slowloris2\": \"Slowrate_DoS\",\n",
        "\n",
        "    # UDP flood\n",
        "    \"UDPFlood1\": \"UDP_Flood\",\n",
        "    \"UDPFlood2\": \"UDP_Flood\",\n",
        "\n",
        "    # SYN flood\n",
        "    \"SYNFlood1\": \"SYN_Flood\",\n",
        "    \"SYNFlood2\": \"SYN_Flood\",\n",
        "\n",
        "    # ICMP flood\n",
        "    \"ICMPFlood1\": \"ICMP_Flood\",\n",
        "    \"ICMPFlood2\": \"ICMP_Flood\",\n",
        "\n",
        "    # Scans\n",
        "    \"UDPScan1\": \"UDP_Scan\",\n",
        "    \"UDPScan2\": \"UDP_Scan\",\n",
        "\n",
        "    \"SYNScan1\": \"SYN_Scan\",\n",
        "    \"SYNScan2\": \"SYN_Scan\",\n",
        "\n",
        "    \"TCPConnect1\": \"TCP_Connect_Scan\",\n",
        "    \"TCPConnect2\": \"TCP_Connect_Scan\",\n",
        "\n",
        "    # Benign (already correct)\n",
        "    \"Benign\": \"Benign\",\n",
        "\n",
        "    # SSH (DROP — not used)\n",
        "    \"SSH1\": None,\n",
        "    \"SSH2\": None\n",
        "}"
      ],
      "metadata": {
        "id": "fZYJaMbzvvTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Label\"] = df[\"Label\"].map(label_map)\n",
        "\n",
        "# Remove rows mapped to None (SSH etc.)\n",
        "df = df.dropna(subset=[\"Label\"])"
      ],
      "metadata": {
        "id": "blRD5HMKv1cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(df[\"Label\"].unique()))\n",
        "print(\"Number of classes:\", df[\"Label\"].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc_diJJrv2na",
        "outputId": "ac379045-2270-4459-be3b-6875c073635b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Benign', 'HTTP_Flood', 'ICMP_Flood', 'SYN_Flood', 'SYN_Scan', 'Slowrate_DoS', 'TCP_Connect_Scan', 'UDP_Flood', 'UDP_Scan']\n",
            "Number of classes: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features & labels\n",
        "X = df.drop(columns=[\"Label\"])\n",
        "y = df[\"Label\"]\n",
        "\n",
        "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Convert to numeric\n",
        "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# Remove inf first\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Fill NaNs BEFORE QT\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "\n",
        "# EXACT 36 features (fixed, no filtering later)\n",
        "X = X.iloc[:, :36]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "y_onehot = tf.keras.utils.to_categorical(y_enc, 9)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y_enc\n",
        ")\n",
        "\n",
        "\n",
        "# Quantile transform (paper style)\n",
        "qt = QuantileTransformer(\n",
        "    n_quantiles=1000,\n",
        "    output_distribution=\"normal\",\n",
        "    random_state=42\n",
        ")\n",
        "X_train = qt.fit_transform(X_train)\n",
        "X_test  = qt.transform(X_test)\n",
        "\n",
        "X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_test  = np.nan_to_num(X_test,  nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "# Reshape\n",
        "X_train = X_train.reshape(-1, 36, 1)\n",
        "X_test  = X_test.reshape(-1, 36, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlaFZwR8v5T6",
        "outputId": "312b3dce-b171-4d39-f024-1e030c22bf5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:1634: RuntimeWarning: All-NaN slice encountered\n",
            "  return fnb._ureduce(a,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NaNs in X:\", np.isnan(X_train).sum())\n",
        "print(\"Infs in X:\", np.isinf(X_test).sum())\n",
        "print(\"y unique sums:\", np.unique(y_train.sum(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j5z-M5Nv5xR",
        "outputId": "866ca5f2-e686-4e1b-e840-b22aeeac760a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaNs in X: 0\n",
            "Infs in X: 0\n",
            "y unique sums: [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wD8DcNkzwDvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XB9LgQVPwEK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MobileNetV1_BiGRU():\n",
        "    inp = Input(shape=(36, 1))\n",
        "\n",
        "    # CNN branch\n",
        "    x = Reshape((36, 1, 1))(inp)\n",
        "    x = Conv2D(32, (3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = DepthwiseConv2D((3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(64, (1,1), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = DepthwiseConv2D((3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(128, (1,1), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    cnn_out = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # GRU branch (conceptual, limited by data)\n",
        "    r = Reshape((36,1))(inp)\n",
        "    r = Bidirectional(GRU(128, return_sequences=True))(r)\n",
        "    r = Bidirectional(GRU(128))(r)\n",
        "\n",
        "    # Projection\n",
        "    merged = Concatenate()([cnn_out, r])\n",
        "    merged = Dense(256, activation=\"relu\")(merged)\n",
        "    merged = Dense(128, activation=\"relu\")(merged)\n",
        "    merged = Dropout(0.5)(merged)\n",
        "\n",
        "    out = Dense(9, activation=\"softmax\")(merged)\n",
        "    return Model(inp, out)\n"
      ],
      "metadata": {
        "id": "pLjqmGGqwA8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MobileNetV1_BiGRU()\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    clipnorm=1.0   # prevents gradient explosions\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=Adam(0.001),\n",
        "#     loss=\"categorical_crossentropy\",\n",
        "#     metrics=[\"accuracy\"]\n",
        "# )\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,                      # originally = 50\n",
        "    batch_size=64,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA6oSMCFwHYB",
        "outputId": "ca73aaac-7761-4a9e-fa17-08df1570f667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 23ms/step - accuracy: 0.7019 - loss: 0.6132 - val_accuracy: 0.7161 - val_loss: 0.5255\n",
            "Epoch 2/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 23ms/step - accuracy: 0.7157 - loss: 0.5325 - val_accuracy: 0.7156 - val_loss: 0.5190\n",
            "Epoch 3/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 24ms/step - accuracy: 0.7173 - loss: 0.5243 - val_accuracy: 0.7170 - val_loss: 0.5160\n",
            "Epoch 4/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 24ms/step - accuracy: 0.7177 - loss: 0.5214 - val_accuracy: 0.7171 - val_loss: 0.5130\n",
            "Epoch 5/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 23ms/step - accuracy: 0.7171 - loss: 0.5213 - val_accuracy: 0.7171 - val_loss: 0.5173\n",
            "Epoch 6/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 23ms/step - accuracy: 0.7171 - loss: 0.5199 - val_accuracy: 0.7153 - val_loss: 0.5156\n",
            "Epoch 7/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 23ms/step - accuracy: 0.7173 - loss: 0.5202 - val_accuracy: 0.7162 - val_loss: 0.5132\n",
            "Epoch 8/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 23ms/step - accuracy: 0.7173 - loss: 0.5196 - val_accuracy: 0.7167 - val_loss: 0.5152\n",
            "Epoch 9/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 23ms/step - accuracy: 0.7176 - loss: 0.5186 - val_accuracy: 0.7177 - val_loss: 0.5149\n",
            "Epoch 10/10\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 23ms/step - accuracy: 0.7171 - loss: 0.5175 - val_accuracy: 0.7171 - val_loss: 0.5102\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78d57cd8c440>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MobileNetV1_BiGRU()\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    clipnorm=1.0   # prevents gradient explosions\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=Adam(0.001),\n",
        "#     loss=\"categorical_crossentropy\",\n",
        "#     metrics=[\"accuracy\"]\n",
        "# )\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,                      # originally = 50\n",
        "    batch_size=64,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qOdZhNV9Q06",
        "outputId": "c6dc4f31-8251-4550-9622-87cde4095f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 23ms/step - accuracy: 0.7027 - loss: 0.6116 - val_accuracy: 0.7168 - val_loss: 0.5252\n",
            "Epoch 2/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 23ms/step - accuracy: 0.7169 - loss: 0.5296 - val_accuracy: 0.7169 - val_loss: 0.5229\n",
            "Epoch 3/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 23ms/step - accuracy: 0.7161 - loss: 0.5240 - val_accuracy: 0.7171 - val_loss: 0.5132\n",
            "Epoch 4/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 23ms/step - accuracy: 0.7168 - loss: 0.5203 - val_accuracy: 0.7164 - val_loss: 0.5128\n",
            "Epoch 5/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 23ms/step - accuracy: 0.7172 - loss: 0.5180 - val_accuracy: 0.7174 - val_loss: 0.5130\n",
            "Epoch 6/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 23ms/step - accuracy: 0.7171 - loss: 0.5180 - val_accuracy: 0.7164 - val_loss: 0.5130\n",
            "Epoch 7/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 24ms/step - accuracy: 0.7179 - loss: 0.5156 - val_accuracy: 0.7169 - val_loss: 0.5105\n",
            "Epoch 8/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 23ms/step - accuracy: 0.7173 - loss: 0.5164 - val_accuracy: 0.7172 - val_loss: 0.5076\n",
            "Epoch 9/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 23ms/step - accuracy: 0.7169 - loss: 0.5166 - val_accuracy: 0.7172 - val_loss: 0.5141\n",
            "Epoch 10/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 23ms/step - accuracy: 0.7162 - loss: 0.5180 - val_accuracy: 0.7171 - val_loss: 0.5239\n",
            "Epoch 11/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 23ms/step - accuracy: 0.7177 - loss: 0.5175 - val_accuracy: 0.7173 - val_loss: 0.5126\n",
            "Epoch 12/20\n",
            "\u001b[1m19020/19020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 23ms/step - accuracy: 0.7173 - loss: 0.5190 - val_accuracy: 0.7171 - val_loss: 0.5145\n",
            "Epoch 13/20\n",
            "\u001b[1m 5294/19020\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:07\u001b[0m 22ms/step - accuracy: 0.7175 - loss: 0.5186"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVozwgOR9L36",
        "outputId": "b28dbd48-9e98-439a-9821-b022c6a2ff31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10567/10567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - accuracy: 0.7124 - loss: 0.5219\n",
            "Test Accuracy: 0.7127165794372559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwaIyT2p9OTC",
        "outputId": "992b8b15-9685-47cf-f0fa-b55ca3d9833d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10567/10567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 5ms/step\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "          Benign       0.50      0.36      0.42     95548\n",
            "      HTTP_Flood       0.94      0.79      0.86     51448\n",
            "      ICMP_Flood       1.00      0.04      0.07      6546\n",
            "       SYN_Flood       0.85      0.19      0.31     11749\n",
            "        SYN_Scan       1.00      0.87      0.93      4595\n",
            "    Slowrate_DoS       0.56      0.30      0.39      8734\n",
            "TCP_Connect_Scan       1.00      0.87      0.93      4660\n",
            "       UDP_Flood       0.72      0.99      0.83    150783\n",
            "        UDP_Scan       1.00      0.77      0.87      4070\n",
            "\n",
            "        accuracy                           0.71    338133\n",
            "       macro avg       0.84      0.58      0.62    338133\n",
            "    weighted avg       0.71      0.71      0.68    338133\n",
            "\n"
          ]
        }
      ]
    }
  ]
}