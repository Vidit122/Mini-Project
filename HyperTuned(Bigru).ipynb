{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLAsq-iQS3Qz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/5G_NIDD_multiclass_clean.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX6BV7FIyv7k",
        "outputId": "28ab9cf6-8b0d-46a7-cd80-0925d64e93a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/5G_NIDD_multiclass_clean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load\n",
        "df = pd.read_csv('/content/drive/MyDrive/5G_NIDD_multiclass_clean.csv', low_memory=False)\n",
        "\n",
        "print(\"Original shape:\", df.shape)\n",
        "\n",
        "# Target\n",
        "y = df['Label']\n",
        "X = df.drop(columns=['Label', 'Attack Type', 'Attack Tool'], errors='ignore')\n",
        "\n",
        "# Remove obvious non-learning columns\n",
        "drop_cols = [\n",
        "    'SrcMac','DstMac','SrcAddr','DstAddr','StartTime','LastTime',\n",
        "    'SrcOui','DstOui'\n",
        "]\n",
        "\n",
        "X = X.drop(columns=[c for c in drop_cols if c in X.columns], errors='ignore')\n",
        "\n",
        "# Keep only numeric features\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "print(\"After numeric selection:\", X.shape)\n"
      ],
      "metadata": {
        "id": "NHzGybXkTf0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23efb390-2579-49da-97b0-cb518b8b8bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (1215890, 112)\n",
            "After numeric selection: (1215890, 86)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "A7ouDUs5ThCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector = SelectKBest(score_func=f_classif, k=36)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"Selected Features:\", selected_features.tolist())\n"
      ],
      "metadata": {
        "id": "BH18Q-jfTiNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3222af13-ef7f-46b6-a1b5-4512e793c88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 1  7 13 14 19 20 21 22 23 24 25 26 27 34 35 36 37 48 49 50 51 57 58 59\n",
            " 60 61 62 63 64 65 66 67 68 69 70 71 72 77 78 79 80] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['Rank', 'Seq', 'Dur', 'RunTime', 'Mean', 'Sum', 'Min', 'Max', 'sTos', 'dTos', 'sTtl', 'dTtl', 'sHops', 'dHops', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes', 'SrcBytes', 'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcWin', 'DstWin', 'sVid', 'dVid', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck', 'AckDat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "num_classes = len(np.unique(y_encoded))\n",
        "print(\"Classes:\", num_classes)\n"
      ],
      "metadata": {
        "id": "ifTb6Y8YTjDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f705d6db-ebb9-4e1c-a95f-63b7f6f47fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y_encoded,\n",
        "    test_size=0.2,\n",
        "    stratify=y_encoded,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "tuCaM7ymTj5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)   # FIT ONLY TRAIN\n",
        "X_test  = scaler.transform(X_test)        # TRANSFORM TEST\n"
      ],
      "metadata": {
        "id": "yKlD4SQTTk1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 36, 1)\n",
        "X_test  = X_test.reshape(-1, 36, 1)\n"
      ],
      "metadata": {
        "id": "h4WwbDFpTmHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def BiGRU_Model(drop_rate=0.5, gru_units=128, dense_units=256):\n",
        "\n",
        "    inp = Input(shape=(36,1))\n",
        "\n",
        "    # Sequence modelling\n",
        "    x = Bidirectional(GRU(gru_units, return_sequences=True))(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Bidirectional(GRU(gru_units))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # classifier\n",
        "    x = Dense(dense_units, activation=\"relu\")(x)\n",
        "    x = Dense(dense_units//2, activation=\"relu\")(x)\n",
        "    x = Dropout(drop_rate)(x)\n",
        "\n",
        "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "vfvZKBB4TnPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "id": "8L8R5xrHTrEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e5c250-b6c2-413a-aa79-d85408354a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.8-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (2.32.4)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (1.76.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (5.29.6)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio->keras-tuner) (4.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2026.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.8-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.8 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "\n",
        "        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "        pt = tf.exp(-ce)\n",
        "        focal = alpha * tf.pow(1 - pt, gamma) * ce\n",
        "\n",
        "        return tf.reduce_mean(focal)\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "ImxHWbjcTsSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights = dict(zip(classes, class_weights))\n",
        "print(class_weights)\n"
      ],
      "metadata": {
        "id": "t-uNmk99TtTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb2e8b7-7981-49d1-cde3-9c9dc81b5350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int64(0): np.float64(0.64811172410117), np.int64(1): np.float64(0.6491671115856914), np.int64(2): np.float64(3.325965944060726), np.int64(3): np.float64(4.20650406504065), np.int64(4): np.float64(37.819284603421465), np.int64(5): np.float64(44.74296228150874), np.int64(6): np.float64(1.3619983757596124), np.int64(7): np.float64(4.309374446216552), np.int64(8): np.float64(5.309563318777292), np.int64(9): np.float64(5.274438781043271), np.int64(10): np.float64(1.9601644365629534), np.int64(11): np.float64(4.803516049382716), np.int64(12): np.float64(5.220652640618291), np.int64(13): np.float64(5.217292426517915), np.int64(14): np.float64(1.5948189926547744), np.int64(15): np.float64(1.9197000197355436), np.int64(16): np.float64(0.12998123867505493), np.int64(17): np.float64(0.21242149215139894), np.int64(18): np.float64(6.053721682847897), np.int64(19): np.float64(5.8995147986414365)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "    model = BiGRU_Model(\n",
        "        drop_rate = hp.Choice(\"dropout\",[0.3,0.5,0.6]),\n",
        "        gru_units = hp.Choice(\"gru_units\",[64,128,256]),\n",
        "        dense_units = hp.Choice(\"dense\",[128,256,512])\n",
        "    )\n",
        "\n",
        "    lr = hp.Choice(\"lr\",[1e-2,1e-3,1e-4])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=focal_loss(gamma=2, alpha=0.25),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=7,\n",
        "    factor=3,\n",
        "    directory=\"tuning_bigru\",\n",
        "    project_name=\"5g_bigru_only\"\n",
        ")\n",
        "\n",
        "# ---- Tune on subset ----\n",
        "sample_idx = np.random.choice(len(X_train), size=int(len(X_train)*0.25), replace=False)\n",
        "X_tune = X_train[sample_idx]\n",
        "y_tune = y_train[sample_idx]\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "tuner.search(\n",
        "    X_tune, y_tune,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    callbacks=[stop_early],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_hps.values)\n"
      ],
      "metadata": {
        "id": "CSNqWucHTuMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61deafb5-e512-4484-967e-f022b3f20b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 03m 56s]\n",
            "val_accuracy: 0.856094241142273\n",
            "\n",
            "Best val_accuracy So Far: 0.8606998920440674\n",
            "Total elapsed time: 00h 23m 56s\n",
            "Best Hyperparameters:\n",
            "{'dropout': 0.5, 'gru_units': 256, 'dense': 256, 'lr': 0.001, 'tuner/epochs': 7, 'tuner/initial_epoch': 3, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0004'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[\n",
        "        EarlyStopping(patience=8, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(patience=4)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "OBBJTFokT1tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebe17b5-d331-4b95-da0e-333349b7a689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 92ms/step - accuracy: 0.7463 - loss: 0.0941 - val_accuracy: 0.8541 - val_loss: 0.0630 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 91ms/step - accuracy: 0.8577 - loss: 0.0400 - val_accuracy: 0.8681 - val_loss: 0.0328 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 91ms/step - accuracy: 0.8734 - loss: 0.0336 - val_accuracy: 0.8931 - val_loss: 0.0260 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 91ms/step - accuracy: 0.8800 - loss: 0.0303 - val_accuracy: 0.8796 - val_loss: 0.0339 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 91ms/step - accuracy: 0.8854 - loss: 0.0285 - val_accuracy: 0.8577 - val_loss: 0.0650 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 91ms/step - accuracy: 0.8824 - loss: 0.0295 - val_accuracy: 0.8854 - val_loss: 0.0279 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 91ms/step - accuracy: 0.8883 - loss: 0.0276 - val_accuracy: 0.8800 - val_loss: 0.0273 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 91ms/step - accuracy: 0.9176 - loss: 0.0219 - val_accuracy: 0.9429 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 92ms/step - accuracy: 0.9339 - loss: 0.0195 - val_accuracy: 0.9430 - val_loss: 0.0173 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 92ms/step - accuracy: 0.9429 - loss: 0.0180 - val_accuracy: 0.9535 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhS54k0GzdFC",
        "outputId": "ce6af20b-a078-4dc3-b6ee-8d4b9f319630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7600/7600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     18761\n",
            "           1       0.98      0.98      0.98     18730\n",
            "           2       0.80      0.92      0.86      3656\n",
            "           3       0.80      0.88      0.83      2890\n",
            "           4       0.36      0.61      0.46       322\n",
            "           5       0.32      0.46      0.38       271\n",
            "           6       0.95      0.98      0.96      8927\n",
            "           7       0.96      0.95      0.95      2822\n",
            "           8       0.92      0.91      0.92      2290\n",
            "           9       0.88      0.90      0.89      2305\n",
            "          10       0.90      0.88      0.89      6203\n",
            "          11       0.71      0.72      0.72      2531\n",
            "          12       0.52      0.81      0.64      2329\n",
            "          13       0.72      0.19      0.30      2331\n",
            "          14       0.98      0.95      0.97      7624\n",
            "          15       0.99      0.98      0.98      6334\n",
            "          16       0.99      0.97      0.98     93543\n",
            "          17       0.96      0.99      0.97     57239\n",
            "          18       0.58      0.89      0.70      2009\n",
            "          19       0.96      0.31      0.46      2061\n",
            "\n",
            "    accuracy                           0.95    243178\n",
            "   macro avg       0.81      0.81      0.79    243178\n",
            "weighted avg       0.96      0.95      0.95    243178\n",
            "\n"
          ]
        }
      ]
    }
  ]
}