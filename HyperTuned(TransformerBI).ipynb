{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4F_mSvlUN7m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load\n",
        "df = pd.read_csv('/content/drive/MyDrive/5G_NIDD_multiclass_clean.csv', low_memory=False)\n",
        "\n",
        "print(\"Original shape:\", df.shape)\n",
        "\n",
        "# Target\n",
        "y = df['Label']\n",
        "X = df.drop(columns=['Label', 'Attack Type', 'Attack Tool'], errors='ignore')\n",
        "\n",
        "# Remove obvious non-learning columns\n",
        "drop_cols = [\n",
        "    'SrcMac','DstMac','SrcAddr','DstAddr','StartTime','LastTime',\n",
        "    'SrcOui','DstOui'\n",
        "]\n",
        "\n",
        "X = X.drop(columns=[c for c in drop_cols if c in X.columns], errors='ignore')\n",
        "\n",
        "# Keep only numeric features\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "print(\"After numeric selection:\", X.shape)\n"
      ],
      "metadata": {
        "id": "RXFNwZj5VHWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403aaf1b-3ce7-4b2d-feda-c1fd26fce178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (1215890, 112)\n",
            "After numeric selection: (1215890, 86)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "0WEVLQcvVILJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector = SelectKBest(score_func=f_classif, k=36)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"Selected Features:\", selected_features.tolist())\n"
      ],
      "metadata": {
        "id": "FQ_v7WjcVJcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4422da-584b-491b-c938-20cbefba835f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 1  7 13 14 19 20 21 22 23 24 25 26 27 34 35 36 37 48 49 50 51 57 58 59\n",
            " 60 61 62 63 64 65 66 67 68 69 70 71 72 77 78 79 80] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['Rank', 'Seq', 'Dur', 'RunTime', 'Mean', 'Sum', 'Min', 'Max', 'sTos', 'dTos', 'sTtl', 'dTtl', 'sHops', 'dHops', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes', 'SrcBytes', 'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcWin', 'DstWin', 'sVid', 'dVid', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck', 'AckDat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "num_classes = len(np.unique(y_encoded))\n",
        "print(\"Classes:\", num_classes)\n"
      ],
      "metadata": {
        "id": "65qXtlqiVLVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a461ef-0faf-4b03-8ec8-d06d7ed9d194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y_encoded,\n",
        "    test_size=0.2,\n",
        "    stratify=y_encoded,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "tzonGSq-VLki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)   # FIT ONLY TRAIN\n",
        "X_test  = scaler.transform(X_test)        # TRANSFORM TEST\n"
      ],
      "metadata": {
        "id": "yMHjgxrSVMfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 36, 1)\n",
        "X_test  = X_test.reshape(-1, 36, 1)\n"
      ],
      "metadata": {
        "id": "zL5UXTEmVNaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, sequence_len, d_model):\n",
        "        super().__init__()\n",
        "        self.pos_encoding = self.positional_encoding(sequence_len, d_model)\n",
        "\n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angle_rates = 1 / tf.pow(10000.0, (2 * (i//2)) / tf.cast(d_model, tf.float32))\n",
        "        return pos * angle_rates\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "\n",
        "        pos = tf.range(position, dtype=tf.float32)[:, tf.newaxis]\n",
        "        i   = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :]\n",
        "\n",
        "        angles = self.get_angles(pos, i, d_model)\n",
        "\n",
        "        # APPLY SIN TO EVEN INDICES\n",
        "        sines = tf.sin(angles[:, 0::2])\n",
        "\n",
        "        # APPLY COS TO ODD INDICES\n",
        "        cosines = tf.cos(angles[:, 1::2])\n",
        "\n",
        "        # Interleave them (NO assignment!)\n",
        "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "\n",
        "        return pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    def call(self, x):\n",
        "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n"
      ],
      "metadata": {
        "id": "x21cqq_mVPVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_block(x, d_model, num_heads, ff_dim, dropout):\n",
        "\n",
        "    head_dim = d_model // num_heads\n",
        "\n",
        "    attn = MultiHeadAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=head_dim\n",
        "    )(x, x)\n",
        "\n",
        "    attn = Dropout(dropout)(attn)\n",
        "    x = LayerNormalization(epsilon=1e-6)(x + attn)\n",
        "\n",
        "    ffn = Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ffn = Dense(d_model)(ffn)\n",
        "    ffn = Dropout(dropout)(ffn)\n",
        "\n",
        "    return LayerNormalization(epsilon=1e-6)(x + ffn)\n",
        "\n"
      ],
      "metadata": {
        "id": "CQk_M7K7VPma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Transformer_IDS(\n",
        "        d_model=64,\n",
        "        num_heads=4,\n",
        "        ff_dim=128,\n",
        "        num_layers=2,\n",
        "        dropout=0.3,\n",
        "        dense_units=256):\n",
        "\n",
        "    inp = Input(shape=(36,1))\n",
        "\n",
        "    # Project features into embedding space\n",
        "    x = Dense(d_model)(inp)\n",
        "\n",
        "    # Add positional encoding\n",
        "    x = PositionalEncoding(36, d_model)(x)\n",
        "\n",
        "    # Stacked Transformer encoders\n",
        "    for _ in range(num_layers):\n",
        "        x = transformer_block(x, d_model, num_heads, ff_dim, dropout)\n",
        "\n",
        "    # Global understanding of traffic\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Classifier\n",
        "    x = Dense(dense_units, activation=\"relu\")(x)\n",
        "    x = Dense(dense_units//2, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "\n",
        "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return Model(inp, out)\n"
      ],
      "metadata": {
        "id": "CJ_KZTz9VYGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "id": "PBz80SGRVRYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a0bdde8-129c-4ffa-c956-395aff3145dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.12/dist-packages (1.4.8)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (2.32.4)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (1.76.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (5.29.6)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio->keras-tuner) (4.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2026.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "\n",
        "        # Prevent log(0)\n",
        "        epsilon = 1e-7\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        # Cross entropy\n",
        "        ce = -y_true * tf.math.log(y_pred)\n",
        "\n",
        "        # Focal weight\n",
        "        weight = alpha * tf.pow(1 - y_pred, gamma)\n",
        "\n",
        "        # Apply focal loss\n",
        "        fl = weight * ce\n",
        "\n",
        "        return tf.reduce_mean(tf.reduce_sum(fl, axis=1))\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Lw_fm-7aVTVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights = dict(zip(classes, class_weights))\n",
        "print(class_weights)\n"
      ],
      "metadata": {
        "id": "UbzDRRaSVUR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47be4e7-9c86-446f-df0d-abf0592b8f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int64(0): np.float64(0.64811172410117), np.int64(1): np.float64(0.6491671115856914), np.int64(2): np.float64(3.325965944060726), np.int64(3): np.float64(4.20650406504065), np.int64(4): np.float64(37.819284603421465), np.int64(5): np.float64(44.74296228150874), np.int64(6): np.float64(1.3619983757596124), np.int64(7): np.float64(4.309374446216552), np.int64(8): np.float64(5.309563318777292), np.int64(9): np.float64(5.274438781043271), np.int64(10): np.float64(1.9601644365629534), np.int64(11): np.float64(4.803516049382716), np.int64(12): np.float64(5.220652640618291), np.int64(13): np.float64(5.217292426517915), np.int64(14): np.float64(1.5948189926547744), np.int64(15): np.float64(1.9197000197355436), np.int64(16): np.float64(0.12998123867505493), np.int64(17): np.float64(0.21242149215139894), np.int64(18): np.float64(6.053721682847897), np.int64(19): np.float64(5.8995147986414365)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test  = to_categorical(y_test, num_classes)\n"
      ],
      "metadata": {
        "id": "8iFVubNALrao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "    model = Transformer_IDS(\n",
        "        d_model = hp.Choice(\"d_model\",[32,64,128]),\n",
        "        num_heads = hp.Choice(\"heads\",[2,4,8]),\n",
        "        ff_dim = hp.Choice(\"ff\",[64,128,256]),\n",
        "        num_layers = hp.Choice(\"layers\",[1,2,3]),\n",
        "        dropout = hp.Choice(\"dropout\",[0.2,0.3,0.5]),\n",
        "        dense_units = hp.Choice(\"dense\",[128,256,512])\n",
        "    )\n",
        "\n",
        "    lr = hp.Choice(\"lr\",[1e-3,1e-4,5e-4])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=focal_loss(gamma=2, alpha=0.25),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=7,\n",
        "    factor=3,\n",
        "    directory=\"tuning_transformer\",\n",
        "    project_name=\"5g_transformer\"\n",
        ")\n",
        "\n",
        "# subset tuning\n",
        "sample_idx = np.random.choice(len(X_train), size=int(len(X_train)*0.25), replace=False)\n",
        "X_tune = X_train[sample_idx]\n",
        "y_tune = y_train[sample_idx]\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "tuner.search(\n",
        "    X_tune, y_tune,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    callbacks=[stop_early],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
        "print(best_hps.values)\n"
      ],
      "metadata": {
        "id": "xSEGffcAVVWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0559c0d3-9c81-4971-9aa5-11506aff309f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 01m 23s]\n",
            "val_accuracy: 0.8756065368652344\n",
            "\n",
            "Best val_accuracy So Far: 0.8756065368652344\n",
            "Total elapsed time: 00h 09m 24s\n",
            "{'d_model': 32, 'heads': 8, 'ff': 64, 'layers': 3, 'dropout': 0.2, 'dense': 256, 'lr': 0.001, 'tuner/epochs': 7, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[\n",
        "        EarlyStopping(patience=8, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(patience=4)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "wl4n6Do0Vkrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c980ddaf-d1ff-411f-de8d-580f82cf83e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 25ms/step - accuracy: 0.6352 - loss: 0.1516 - val_accuracy: 0.8341 - val_loss: 0.0485 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 17ms/step - accuracy: 0.8292 - loss: 0.0475 - val_accuracy: 0.8661 - val_loss: 0.0317 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8671 - loss: 0.0340 - val_accuracy: 0.8999 - val_loss: 0.0260 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8768 - loss: 0.0298 - val_accuracy: 0.8800 - val_loss: 0.0275 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8845 - loss: 0.0274 - val_accuracy: 0.9000 - val_loss: 0.0220 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8911 - loss: 0.0261 - val_accuracy: 0.8864 - val_loss: 0.0239 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.8972 - loss: 0.0247 - val_accuracy: 0.9131 - val_loss: 0.0192 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.9043 - loss: 0.0223 - val_accuracy: 0.9162 - val_loss: 0.0199 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.9044 - loss: 0.0227 - val_accuracy: 0.9066 - val_loss: 0.0238 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.9074 - loss: 0.0215 - val_accuracy: 0.9020 - val_loss: 0.0207 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.shape)\n",
        "# print(pred_probs.shape)\n",
        "print(np.unique(y_test)[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPIERLm_PydE",
        "outputId": "eb71cac7-93e8-43f9-85a6-5d1d735c8a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(243178, 20)\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "pred_probs = model.predict(X_test)\n",
        "pred = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "print(classification_report(y_test, pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vowVs9a3MDQ6",
        "outputId": "e5609810-4c8a-48f2-86fb-2b44360fb526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7600/7600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     18761\n",
            "           1       0.98      0.94      0.96     18730\n",
            "           2       0.56      0.91      0.69      3656\n",
            "           3       0.74      0.92      0.82      2890\n",
            "           4       0.38      0.66      0.49       322\n",
            "           5       0.37      0.17      0.24       271\n",
            "           6       0.96      0.75      0.84      8927\n",
            "           7       0.79      0.75      0.77      2822\n",
            "           8       0.94      0.90      0.92      2290\n",
            "           9       0.97      0.88      0.92      2305\n",
            "          10       0.87      0.84      0.85      6203\n",
            "          11       0.66      0.64      0.65      2531\n",
            "          12       0.47      0.93      0.63      2329\n",
            "          13       0.36      0.00      0.00      2331\n",
            "          14       0.93      0.94      0.94      7624\n",
            "          15       0.98      0.96      0.97      6334\n",
            "          16       0.97      0.92      0.95     93543\n",
            "          17       0.88      0.97      0.92     57239\n",
            "          18       0.91      0.53      0.67      2009\n",
            "          19       0.68      0.87      0.76      2061\n",
            "\n",
            "    accuracy                           0.91    243178\n",
            "   macro avg       0.77      0.77      0.75    243178\n",
            "weighted avg       0.92      0.91      0.91    243178\n",
            "\n"
          ]
        }
      ]
    }
  ]
}