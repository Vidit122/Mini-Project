{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYwU5rFlPARN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load\n",
        "df = pd.read_csv(\"5G_NIDD_multiclass_clean.csv\", low_memory=False)\n",
        "\n",
        "print(\"Original shape:\", df.shape)\n",
        "\n",
        "# Target\n",
        "y = df['Label']\n",
        "X = df.drop(columns=['Label', 'Attack Type', 'Attack Tool'], errors='ignore')\n",
        "\n",
        "# Remove obvious non-learning columns\n",
        "drop_cols = [\n",
        "    'SrcMac','DstMac','SrcAddr','DstAddr','StartTime','LastTime',\n",
        "    'SrcOui','DstOui'\n",
        "]\n",
        "\n",
        "X = X.drop(columns=[c for c in drop_cols if c in X.columns], errors='ignore')\n",
        "\n",
        "# Keep only numeric features\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "print(\"After numeric selection:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDVdZA3BRgyY",
        "outputId": "1390fa1c-07e7-4e7b-edb2-6c90f4225d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (1215890, 112)\n",
            "After numeric selection: (1215890, 86)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "AM11chdmRhNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector = SelectKBest(score_func=f_classif, k=36)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"Selected Features:\", selected_features.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCeDPzEmRibV",
        "outputId": "5ab59fd5-0438-46f9-d030-a9147b8a9673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 1  7 13 14 19 20 21 22 23 24 25 26 27 34 35 36 37 48 49 50 51 57 58 59\n",
            " 60 61 62 63 64 65 66 67 68 69 70 71 72 77 78 79 80] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['Rank', 'Seq', 'Dur', 'RunTime', 'Mean', 'Sum', 'Min', 'Max', 'sTos', 'dTos', 'sTtl', 'dTtl', 'sHops', 'dHops', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes', 'SrcBytes', 'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcWin', 'DstWin', 'sVid', 'dVid', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck', 'AckDat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "num_classes = len(np.unique(y_encoded))\n",
        "print(\"Classes:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ppx_VEPRort",
        "outputId": "1147f1c2-0b80-47ea-ac11-b5106a2fac18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y_encoded,\n",
        "    test_size=0.2,\n",
        "    stratify=y_encoded,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "dr0AVIaARqGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)   # FIT ONLY TRAIN\n",
        "X_test  = scaler.transform(X_test)        # TRANSFORM TEST\n"
      ],
      "metadata": {
        "id": "s1ILFQdoRrsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 36, 1)\n",
        "X_test  = X_test.reshape(-1, 36, 1)\n"
      ],
      "metadata": {
        "id": "48oYaa5_RtAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MobileNetV1(drop_rate=0.5, dense_units=256, width_mult=1.0):\n",
        "\n",
        "    inp = Input(shape=(36,1))\n",
        "\n",
        "    x = Reshape((36,1,1))(inp)\n",
        "\n",
        "    # Initial conv\n",
        "    x = Conv2D(int(32*width_mult),(3,3),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise Block 1\n",
        "    x = DepthwiseConv2D((3,3),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(int(64*width_mult),(1,1),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise Block 2\n",
        "    x = DepthwiseConv2D((3,3),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(int(128*width_mult),(1,1),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Classifier\n",
        "    x = Dense(dense_units, activation=\"relu\")(x)\n",
        "    x = Dense(dense_units//2, activation=\"relu\")(x)\n",
        "    x = Dropout(drop_rate)(x)\n",
        "\n",
        "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "TsdDtGLxRzxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vENW9MATSEYF",
        "outputId": "bbf95f94-796f-43ad-c6d9-29844a597655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.8-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (2.32.4)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (1.76.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (5.29.6)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio->keras-tuner) (4.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2026.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.8-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.8 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "\n",
        "        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "        pt = tf.exp(-ce)\n",
        "        focal = alpha * tf.pow(1 - pt, gamma) * ce\n",
        "\n",
        "        return tf.reduce_mean(focal)\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "h0WTnH4FSIAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights = dict(zip(classes, class_weights))\n",
        "print(class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD2kJdxKSKX1",
        "outputId": "234c8581-0e50-4131-93ba-93f0433f5dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int64(0): np.float64(0.64811172410117), np.int64(1): np.float64(0.6491671115856914), np.int64(2): np.float64(3.325965944060726), np.int64(3): np.float64(4.20650406504065), np.int64(4): np.float64(37.819284603421465), np.int64(5): np.float64(44.74296228150874), np.int64(6): np.float64(1.3619983757596124), np.int64(7): np.float64(4.309374446216552), np.int64(8): np.float64(5.309563318777292), np.int64(9): np.float64(5.274438781043271), np.int64(10): np.float64(1.9601644365629534), np.int64(11): np.float64(4.803516049382716), np.int64(12): np.float64(5.220652640618291), np.int64(13): np.float64(5.217292426517915), np.int64(14): np.float64(1.5948189926547744), np.int64(15): np.float64(1.9197000197355436), np.int64(16): np.float64(0.12998123867505493), np.int64(17): np.float64(0.21242149215139894), np.int64(18): np.float64(6.053721682847897), np.int64(19): np.float64(5.8995147986414365)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "    model = MobileNetV1(\n",
        "        drop_rate = hp.Choice(\"dropout\",[0.3,0.5,0.6]),\n",
        "        dense_units = hp.Choice(\"dense\",[128,256,512]),\n",
        "        width_mult = hp.Choice(\"width\",[0.75,1.0,1.25])\n",
        "    )\n",
        "\n",
        "    lr = hp.Choice(\"lr\",[1e-2,1e-3,1e-4])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=focal_loss(gamma=2, alpha=0.25),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=7,\n",
        "    factor=3,\n",
        "    directory=\"tuning_mobilenet\",\n",
        "    project_name=\"5g_mobilenet_only\"\n",
        ")\n",
        "\n",
        "# ---- Tune on subset ----\n",
        "sample_idx = np.random.choice(len(X_train), size=int(len(X_train)*0.25), replace=False)\n",
        "X_tune = X_train[sample_idx]\n",
        "y_tune = y_train[sample_idx]\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "tuner.search(\n",
        "    X_tune, y_tune,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    callbacks=[stop_early],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_hps.values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJjmRI5ZSOSs",
        "outputId": "39cecd16-1195-4c13-82bb-2f49a8b2c460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 01m 00s]\n",
            "val_accuracy: 0.7603009939193726\n",
            "\n",
            "Best val_accuracy So Far: 0.8472942113876343\n",
            "Total elapsed time: 00h 07m 57s\n",
            "Best Hyperparameters:\n",
            "{'dropout': 0.3, 'dense': 512, 'width': 1.0, 'lr': 0.01, 'tuner/epochs': 7, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[\n",
        "        EarlyStopping(patience=8, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(patience=4)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn4WHpwISmO1",
        "outputId": "b8626c40-3513-4ccc-f48b-12f24dfedc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 22ms/step - accuracy: 0.6911 - loss: 0.1079 - val_accuracy: 0.7689 - val_loss: 0.0767 - learning_rate: 0.0100\n",
            "Epoch 2/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8469 - loss: 0.0419 - val_accuracy: 0.8327 - val_loss: 0.0427 - learning_rate: 0.0100\n",
            "Epoch 3/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8537 - loss: 0.0380 - val_accuracy: 0.8535 - val_loss: 0.0415 - learning_rate: 0.0100\n",
            "Epoch 4/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8584 - loss: 0.0361 - val_accuracy: 0.8227 - val_loss: 0.0447 - learning_rate: 0.0100\n",
            "Epoch 5/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8634 - loss: 0.0341 - val_accuracy: 0.8502 - val_loss: 0.0406 - learning_rate: 0.0100\n",
            "Epoch 6/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8672 - loss: 0.0329 - val_accuracy: 0.8718 - val_loss: 0.0298 - learning_rate: 0.0100\n",
            "Epoch 7/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8687 - loss: 0.0325 - val_accuracy: 0.8339 - val_loss: 0.0547 - learning_rate: 0.0100\n",
            "Epoch 8/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8722 - loss: 0.0316 - val_accuracy: 0.8345 - val_loss: 0.0563 - learning_rate: 0.0100\n",
            "Epoch 9/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8729 - loss: 0.0313 - val_accuracy: 0.8117 - val_loss: 0.1154 - learning_rate: 0.0100\n",
            "Epoch 10/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8747 - loss: 0.0312 - val_accuracy: 0.7857 - val_loss: 0.1306 - learning_rate: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk0EKzjAaMuE",
        "outputId": "42bfc749-c0be-42c4-f942-56dd06d673ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7600/7600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     18761\n",
            "           1       0.96      0.92      0.94     18730\n",
            "           2       0.39      0.49      0.44      3656\n",
            "           3       0.43      0.88      0.57      2890\n",
            "           4       0.30      0.75      0.43       322\n",
            "           5       0.41      0.14      0.21       271\n",
            "           6       0.93      0.75      0.83      8927\n",
            "           7       0.76      0.54      0.63      2822\n",
            "           8       0.99      0.87      0.93      2290\n",
            "           9       1.00      0.87      0.93      2305\n",
            "          10       0.79      0.83      0.81      6203\n",
            "          11       0.56      0.50      0.53      2531\n",
            "          12       0.27      0.01      0.03      2329\n",
            "          13       0.48      0.88      0.62      2331\n",
            "          14       0.96      0.92      0.94      7624\n",
            "          15       0.98      0.96      0.97      6334\n",
            "          16       0.98      0.85      0.91     93543\n",
            "          17       0.80      0.99      0.89     57239\n",
            "          18       0.41      0.06      0.11      2009\n",
            "          19       0.51      0.83      0.63      2061\n",
            "\n",
            "    accuracy                           0.87    243178\n",
            "   macro avg       0.70      0.70      0.67    243178\n",
            "weighted avg       0.89      0.87      0.87    243178\n",
            "\n"
          ]
        }
      ]
    }
  ]
}