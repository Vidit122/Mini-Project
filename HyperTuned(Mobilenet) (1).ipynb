{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KYwU5rFlPARN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load\n",
        "df = pd.read_csv('/content/drive/MyDrive/5G_NIDD_multiclass_clean.csv', low_memory=False)\n",
        "\n",
        "print(\"Original shape:\", df.shape)\n",
        "\n",
        "# Target\n",
        "y = df['Label']\n",
        "X = df.drop(columns=['Label', 'Attack Type', 'Attack Tool'], errors='ignore')\n",
        "\n",
        "# Remove obvious non-learning columns\n",
        "drop_cols = [\n",
        "    'SrcMac','DstMac','SrcAddr','DstAddr','StartTime','LastTime',\n",
        "    'SrcOui','DstOui'\n",
        "]\n",
        "\n",
        "X = X.drop(columns=[c for c in drop_cols if c in X.columns], errors='ignore')\n",
        "\n",
        "# Keep only numeric features\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "print(\"After numeric selection:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDVdZA3BRgyY",
        "outputId": "171d1a36-03aa-461c-fa95-76a07fbe99fd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (1215890, 112)\n",
            "After numeric selection: (1215890, 86)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "AM11chdmRhNW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector = SelectKBest(score_func=f_classif, k=36)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"Selected Features:\", selected_features.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCeDPzEmRibV",
        "outputId": "22bb53f6-8131-43cf-97ea-be7bcdb317f3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 1  7 13 14 19 20 21 22 23 24 25 26 27 34 35 36 37 48 49 50 51 57 58 59\n",
            " 60 61 62 63 64 65 66 67 68 69 70 71 72 77 78 79 80] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['Rank', 'Seq', 'Dur', 'RunTime', 'Mean', 'Sum', 'Min', 'Max', 'sTos', 'dTos', 'sTtl', 'dTtl', 'sHops', 'dHops', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes', 'SrcBytes', 'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcWin', 'DstWin', 'sVid', 'dVid', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck', 'AckDat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "num_classes = len(np.unique(y_encoded))\n",
        "print(\"Classes:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ppx_VEPRort",
        "outputId": "51789782-b90c-41f0-ee92-c9cdfd7dd023"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y_encoded,\n",
        "    test_size=0.2,\n",
        "    stratify=y_encoded,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "dr0AVIaARqGF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)   # FIT ONLY TRAIN\n",
        "X_test  = scaler.transform(X_test)        # TRANSFORM TEST\n"
      ],
      "metadata": {
        "id": "s1ILFQdoRrsl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 36, 1)\n",
        "X_test  = X_test.reshape(-1, 36, 1)\n"
      ],
      "metadata": {
        "id": "48oYaa5_RtAN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MobileNetV1(drop_rate=0.5, dense_units=256, width_mult=1.0):\n",
        "\n",
        "    inp = Input(shape=(36,1))\n",
        "\n",
        "    x = Reshape((36,1,1))(inp)\n",
        "\n",
        "    # Initial conv\n",
        "    x = Conv2D(int(32*width_mult),(3,3),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise Block 1\n",
        "    x = DepthwiseConv2D((3,3),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(int(64*width_mult),(1,1),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise Block 2\n",
        "    x = DepthwiseConv2D((3,3),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(int(128*width_mult),(1,1),padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Classifier\n",
        "    x = Dense(dense_units, activation=\"relu\")(x)\n",
        "    x = Dense(dense_units//2, activation=\"relu\")(x)\n",
        "    x = Dropout(drop_rate)(x)\n",
        "\n",
        "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "TsdDtGLxRzxv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vENW9MATSEYF",
        "outputId": "d948f41d-4cb1-4dfb-a7ef-11a842d5b740"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.12/dist-packages (1.4.8)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (2.32.4)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (1.78.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (5.29.6)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio->keras-tuner) (4.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2026.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "\n",
        "        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "        pt = tf.exp(-ce)\n",
        "        focal = alpha * tf.pow(1 - pt, gamma) * ce\n",
        "\n",
        "        return tf.reduce_mean(focal)\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "h0WTnH4FSIAF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights = dict(zip(classes, class_weights))\n",
        "print(class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD2kJdxKSKX1",
        "outputId": "c75efba3-5259-4354-ce7a-1fe21841681f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int64(0): np.float64(0.64811172410117), np.int64(1): np.float64(0.6491671115856914), np.int64(2): np.float64(3.325965944060726), np.int64(3): np.float64(4.20650406504065), np.int64(4): np.float64(37.819284603421465), np.int64(5): np.float64(44.74296228150874), np.int64(6): np.float64(1.3619983757596124), np.int64(7): np.float64(4.309374446216552), np.int64(8): np.float64(5.309563318777292), np.int64(9): np.float64(5.274438781043271), np.int64(10): np.float64(1.9601644365629534), np.int64(11): np.float64(4.803516049382716), np.int64(12): np.float64(5.220652640618291), np.int64(13): np.float64(5.217292426517915), np.int64(14): np.float64(1.5948189926547744), np.int64(15): np.float64(1.9197000197355436), np.int64(16): np.float64(0.12998123867505493), np.int64(17): np.float64(0.21242149215139894), np.int64(18): np.float64(6.053721682847897), np.int64(19): np.float64(5.8995147986414365)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "    model = MobileNetV1(\n",
        "        drop_rate = hp.Choice(\"dropout\",[0.3,0.5,0.6]),\n",
        "        dense_units = hp.Choice(\"dense\",[128,256,512]),\n",
        "        width_mult = hp.Choice(\"width\",[0.75,1.0,1.25])\n",
        "    )\n",
        "\n",
        "    lr = hp.Choice(\"lr\",[1e-2,1e-3,1e-4])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=focal_loss(gamma=2, alpha=0.25),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=7,\n",
        "    factor=3,\n",
        "    directory=\"tuning_mobilenet\",\n",
        "    project_name=\"5g_mobilenet_only\"\n",
        ")\n",
        "\n",
        "# ---- Tune on subset ----\n",
        "sample_idx = np.random.choice(len(X_train), size=int(len(X_train)*1), replace=False)\n",
        "X_tune = X_train[sample_idx]\n",
        "y_tune = y_train[sample_idx]\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "tuner.search(\n",
        "    X_tune, y_tune,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    callbacks=[stop_early],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_hps.values)\n"
      ],
      "metadata": {
        "id": "zJjmRI5ZSOSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=15,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[\n",
        "        EarlyStopping(patience=8, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(patience=4)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn4WHpwISmO1",
        "outputId": "a6daa1e2-0782-4e7d-d644-e71f604797a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.6853 - loss: 0.1020 - val_accuracy: 0.7890 - val_loss: 0.0915 - learning_rate: 0.0100\n",
            "Epoch 2/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.8352 - loss: 0.0461 - val_accuracy: 0.8441 - val_loss: 0.0407 - learning_rate: 0.0100\n",
            "Epoch 3/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8491 - loss: 0.0402 - val_accuracy: 0.8244 - val_loss: 0.0522 - learning_rate: 0.0100\n",
            "Epoch 4/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8555 - loss: 0.0375 - val_accuracy: 0.8525 - val_loss: 0.0386 - learning_rate: 0.0100\n",
            "Epoch 5/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8582 - loss: 0.0362 - val_accuracy: 0.8596 - val_loss: 0.0445 - learning_rate: 0.0100\n",
            "Epoch 6/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8601 - loss: 0.0357 - val_accuracy: 0.8575 - val_loss: 0.0402 - learning_rate: 0.0100\n",
            "Epoch 7/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8689 - loss: 0.0329 - val_accuracy: 0.7140 - val_loss: 0.2080 - learning_rate: 0.0100\n",
            "Epoch 8/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 14ms/step - accuracy: 0.8657 - loss: 0.0335 - val_accuracy: 0.8697 - val_loss: 0.0334 - learning_rate: 0.0100\n",
            "Epoch 9/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8739 - loss: 0.0313 - val_accuracy: 0.8268 - val_loss: 0.0528 - learning_rate: 0.0100\n",
            "Epoch 10/10\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8730 - loss: 0.0313 - val_accuracy: 0.8736 - val_loss: 0.0317 - learning_rate: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk0EKzjAaMuE",
        "outputId": "146cbf0c-dfc1-4b8b-bd4d-508c8854b28b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7600/7600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97     18761\n",
            "           1       0.90      0.93      0.92     18730\n",
            "           2       0.51      0.86      0.64      3656\n",
            "           3       0.73      0.79      0.76      2890\n",
            "           4       0.40      0.41      0.41       322\n",
            "           5       0.29      0.20      0.23       271\n",
            "           6       0.92      0.91      0.92      8927\n",
            "           7       0.84      0.38      0.53      2822\n",
            "           8       0.98      0.88      0.93      2290\n",
            "           9       0.99      0.87      0.93      2305\n",
            "          10       0.82      0.68      0.74      6203\n",
            "          11       0.45      0.56      0.50      2531\n",
            "          12       0.39      0.17      0.23      2329\n",
            "          13       0.50      0.75      0.60      2331\n",
            "          14       0.84      0.93      0.88      7624\n",
            "          15       1.00      0.81      0.89      6334\n",
            "          16       0.97      0.86      0.91     93543\n",
            "          17       0.81      0.97      0.89     57239\n",
            "          18       0.52      0.31      0.39      2009\n",
            "          19       0.57      0.72      0.64      2061\n",
            "\n",
            "    accuracy                           0.87    243178\n",
            "   macro avg       0.72      0.70      0.70    243178\n",
            "weighted avg       0.88      0.87      0.87    243178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# remove previous runs\n",
        "if os.path.exists(\"tuning_mobilenet\"):\n",
        "    shutil.rmtree(\"tuning_mobilenet\")\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "    model = MobileNetV1(\n",
        "        drop_rate = hp.Float(\"dropout\", 0.2, 0.7, step=0.1),\n",
        "        dense_units = hp.Int(\"dense\", 128, 512, step=64),\n",
        "        width_mult = hp.Float(\"width\", 0.5, 1.5, step=0.25)\n",
        "    )\n",
        "\n",
        "    lr = hp.Float(\"lr\", 1e-5, 1e-2, sampling=\"log\")\n",
        "\n",
        "    model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "    return model\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=7,\n",
        "    factor=3,\n",
        "    directory=\"tuning_mobilenet\",\n",
        "    project_name=\"5g_mobilenet_only\"\n",
        ")\n",
        "\n",
        "# ---- Tune on subset ----\n",
        "sample_idx = np.random.choice(len(X_train), size=int(len(X_train)*1), replace=False)\n",
        "X_tune = X_train[sample_idx]\n",
        "y_tune = y_train[sample_idx]\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "tuner.search(\n",
        "    X_tune, y_tune,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    callbacks=[stop_early],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_hps.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrQKr5PpqKnz",
        "outputId": "18a9b050-0256-4777-9708-8d26cdd19b68"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 02m 10s]\n",
            "val_accuracy: 0.8091784119606018\n",
            "\n",
            "Best val_accuracy So Far: 0.8747732043266296\n",
            "Total elapsed time: 00h 21m 20s\n",
            "Best Hyperparameters:\n",
            "{'dropout': 0.30000000000000004, 'dense': 448, 'width': 0.75, 'lr': 0.009658312491068482, 'tuner/epochs': 7, 'tuner/initial_epoch': 3, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=15,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[\n",
        "        EarlyStopping(patience=8, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(patience=4)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWwUpQH3ruFS",
        "outputId": "108bf511-e64e-4a73-e1c8-ade96d2a63bb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 18ms/step - accuracy: 0.5970 - loss: 1.4896 - val_accuracy: 0.7904 - val_loss: 0.5285 - learning_rate: 0.0097\n",
            "Epoch 2/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8087 - loss: 0.8543 - val_accuracy: 0.4121 - val_loss: 3.5513 - learning_rate: 0.0097\n",
            "Epoch 3/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8189 - loss: 0.7657 - val_accuracy: 0.7741 - val_loss: 0.6440 - learning_rate: 0.0097\n",
            "Epoch 4/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8477 - loss: 0.7075 - val_accuracy: 0.8459 - val_loss: 0.3785 - learning_rate: 0.0097\n",
            "Epoch 5/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8516 - loss: 0.6871 - val_accuracy: 0.8569 - val_loss: 0.3296 - learning_rate: 0.0097\n",
            "Epoch 6/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8564 - loss: 0.6594 - val_accuracy: 0.8453 - val_loss: 0.4622 - learning_rate: 0.0097\n",
            "Epoch 7/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8605 - loss: 0.6347 - val_accuracy: 0.8329 - val_loss: 0.5347 - learning_rate: 0.0097\n",
            "Epoch 8/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8493 - loss: 0.6418 - val_accuracy: 0.8573 - val_loss: 0.3869 - learning_rate: 0.0097\n",
            "Epoch 9/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8600 - loss: 0.6279 - val_accuracy: 0.7901 - val_loss: 1.0033 - learning_rate: 0.0097\n",
            "Epoch 10/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8723 - loss: 0.5586 - val_accuracy: 0.8448 - val_loss: 0.5455 - learning_rate: 9.6583e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8803 - loss: 0.5132 - val_accuracy: 0.8550 - val_loss: 0.4693 - learning_rate: 9.6583e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8815 - loss: 0.5066 - val_accuracy: 0.8131 - val_loss: 0.9488 - learning_rate: 9.6583e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8835 - loss: 0.4897 - val_accuracy: 0.8388 - val_loss: 0.6180 - learning_rate: 9.6583e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb02Uy9-s8Tt",
        "outputId": "d2b928c0-1aeb-42a8-947c-b32eee575959"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7600/7600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97     18761\n",
            "           1       0.97      0.88      0.92     18730\n",
            "           2       0.32      0.45      0.37      3656\n",
            "           3       0.31      0.94      0.47      2890\n",
            "           4       0.22      0.68      0.34       322\n",
            "           5       0.21      0.20      0.20       271\n",
            "           6       0.97      0.68      0.80      8927\n",
            "           7       0.71      0.63      0.67      2822\n",
            "           8       0.99      0.87      0.93      2290\n",
            "           9       0.94      0.88      0.91      2305\n",
            "          10       0.83      0.60      0.70      6203\n",
            "          11       0.45      0.77      0.57      2531\n",
            "          12       0.48      0.58      0.53      2329\n",
            "          13       0.48      0.36      0.41      2331\n",
            "          14       0.96      0.89      0.92      7624\n",
            "          15       0.98      0.93      0.96      6334\n",
            "          16       0.99      0.84      0.91     93543\n",
            "          17       0.80      0.98      0.88     57239\n",
            "          18       0.42      0.11      0.17      2009\n",
            "          19       0.51      0.81      0.63      2061\n",
            "\n",
            "    accuracy                           0.86    243178\n",
            "   macro avg       0.68      0.70      0.66    243178\n",
            "weighted avg       0.89      0.86      0.86    243178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=25,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[\n",
        "        EarlyStopping(patience=8, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(patience=4)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_IfSqtjyB_D",
        "outputId": "0fe0f618-756a-49c0-8b94-f09bbe1af077"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.6029 - loss: 1.4194 - val_accuracy: 0.6781 - val_loss: 1.0280 - learning_rate: 0.0097\n",
            "Epoch 2/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8318 - loss: 0.7886 - val_accuracy: 0.6242 - val_loss: 1.9196 - learning_rate: 0.0097\n",
            "Epoch 3/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8416 - loss: 0.7304 - val_accuracy: 0.6996 - val_loss: 1.0300 - learning_rate: 0.0097\n",
            "Epoch 4/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8538 - loss: 0.6740 - val_accuracy: 0.6786 - val_loss: 2.2844 - learning_rate: 0.0097\n",
            "Epoch 5/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8514 - loss: 0.6626 - val_accuracy: 0.8478 - val_loss: 0.3574 - learning_rate: 0.0097\n",
            "Epoch 6/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8582 - loss: 0.6405 - val_accuracy: 0.8536 - val_loss: 0.3375 - learning_rate: 0.0097\n",
            "Epoch 7/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8620 - loss: 0.6170 - val_accuracy: 0.8389 - val_loss: 0.4894 - learning_rate: 0.0097\n",
            "Epoch 8/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8622 - loss: 0.6212 - val_accuracy: 0.8447 - val_loss: 0.4769 - learning_rate: 0.0097\n",
            "Epoch 9/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8650 - loss: 0.5950 - val_accuracy: 0.8680 - val_loss: 0.2806 - learning_rate: 0.0097\n",
            "Epoch 10/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8668 - loss: 0.5893 - val_accuracy: 0.8186 - val_loss: 0.7195 - learning_rate: 0.0097\n",
            "Epoch 11/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8672 - loss: 0.5929 - val_accuracy: 0.8376 - val_loss: 0.8167 - learning_rate: 0.0097\n",
            "Epoch 12/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8701 - loss: 0.5731 - val_accuracy: 0.8292 - val_loss: 0.6238 - learning_rate: 0.0097\n",
            "Epoch 13/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8713 - loss: 0.5772 - val_accuracy: 0.8414 - val_loss: 0.6512 - learning_rate: 0.0097\n",
            "Epoch 14/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8880 - loss: 0.4845 - val_accuracy: 0.8597 - val_loss: 0.6115 - learning_rate: 9.6583e-04\n",
            "Epoch 15/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8938 - loss: 0.4566 - val_accuracy: 0.8183 - val_loss: 1.4829 - learning_rate: 9.6583e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8965 - loss: 0.4414 - val_accuracy: 0.8168 - val_loss: 1.5482 - learning_rate: 9.6583e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m1710/1710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8978 - loss: 0.4331 - val_accuracy: 0.8281 - val_loss: 1.2531 - learning_rate: 9.6583e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxTJ5vtFyFau",
        "outputId": "99585f0f-b09d-4413-eaf3-517508ea6f5f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7600/7600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98     18761\n",
            "           1       0.99      0.90      0.94     18730\n",
            "           2       0.41      0.63      0.49      3656\n",
            "           3       0.50      0.83      0.62      2890\n",
            "           4       0.18      0.87      0.30       322\n",
            "           5       0.17      0.27      0.21       271\n",
            "           6       0.99      0.76      0.86      8927\n",
            "           7       0.77      0.62      0.69      2822\n",
            "           8       0.98      0.87      0.93      2290\n",
            "           9       0.99      0.87      0.93      2305\n",
            "          10       0.89      0.62      0.73      6203\n",
            "          11       0.35      0.88      0.50      2531\n",
            "          12       0.45      0.55      0.49      2329\n",
            "          13       0.53      0.43      0.48      2331\n",
            "          14       0.89      0.93      0.91      7624\n",
            "          15       0.98      0.88      0.93      6334\n",
            "          16       0.99      0.85      0.91     93543\n",
            "          17       0.81      0.98      0.88     57239\n",
            "          18       0.50      0.86      0.63      2009\n",
            "          19       0.94      0.10      0.18      2061\n",
            "\n",
            "    accuracy                           0.87    243178\n",
            "   macro avg       0.72      0.73      0.68    243178\n",
            "weighted avg       0.90      0.87      0.87    243178\n",
            "\n"
          ]
        }
      ]
    }
  ]
}