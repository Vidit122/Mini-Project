{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAdxxjcsDJXvQcgiHCIlT6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vidit122/Mini-Project/blob/main/FinalMobileNetV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "VJVAwxRBsfJw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJwUw_ubrhvU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Reshape, Conv2D, DepthwiseConv2D,\n",
        "    BatchNormalization, ReLU, GlobalAveragePooling2D,\n",
        "    Bidirectional, GRU, Dense, Dropout, Concatenate\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"5G_NIDD_FULL_9CLASS_MIXED.csv\", low_memory=False)\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns[:10])\n",
        "print(df[\"Label\"].value_counts())\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns[:10])\n",
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zCB02DGrmjo",
        "outputId": "9896330e-a504-435a-909b-53012a4907d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1693627, 51)\n",
            "Index(['Max', 'AckDat', 'DstLoss', 'dDSb', 'Sum', 'Mean', 'SrcTCPBase', 'sDSb',\n",
            "       'dTtl', 'TotBytes'],\n",
            "      dtype='object')\n",
            "Label\n",
            "Benign         477737\n",
            "UDPFlood1      467717\n",
            "UDPFlood2      286197\n",
            "Goldeneye1      93803\n",
            "Goldeneye2      93650\n",
            "SYNFlood1       44636\n",
            "Torshammer1     38120\n",
            "Torshammer2     31669\n",
            "Slowloris1      31015\n",
            "ICMPFlood1      18279\n",
            "ICMPFlood2      14452\n",
            "SYNFlood2       14108\n",
            "Slowloris2      12656\n",
            "TCPConnect2     11653\n",
            "TCPConnect1     11645\n",
            "SYNScan2        11526\n",
            "SYNScan1        11450\n",
            "UDPScan2        10305\n",
            "UDPScan1        10043\n",
            "SSH1             1608\n",
            "SSH2             1358\n",
            "Name: count, dtype: int64\n",
            "(1693627, 51)\n",
            "Index(['Max', 'AckDat', 'DstLoss', 'dDSb', 'Sum', 'Mean', 'SrcTCPBase', 'sDSb',\n",
            "       'dTtl', 'TotBytes'],\n",
            "      dtype='object')\n",
            "Label\n",
            "Benign         477737\n",
            "UDPFlood1      467717\n",
            "UDPFlood2      286197\n",
            "Goldeneye1      93803\n",
            "Goldeneye2      93650\n",
            "SYNFlood1       44636\n",
            "Torshammer1     38120\n",
            "Torshammer2     31669\n",
            "Slowloris1      31015\n",
            "ICMPFlood1      18279\n",
            "ICMPFlood2      14452\n",
            "SYNFlood2       14108\n",
            "Slowloris2      12656\n",
            "TCPConnect2     11653\n",
            "TCPConnect1     11645\n",
            "SYNScan2        11526\n",
            "SYNScan1        11450\n",
            "UDPScan2        10305\n",
            "UDPScan1        10043\n",
            "SSH1             1608\n",
            "SSH2             1358\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ALWAYS start from df\n",
        "X = df.drop(columns=[\"Label\"])\n",
        "y = df[\"Label\"]\n",
        "\n",
        "# Force numeric\n",
        "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "print(\"X shape BEFORE slicing:\", X.shape)\n",
        " # MUST be > 36 columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUYTbNK6rqJx",
        "outputId": "8aa75d88-4533-4b04-c899-432493b20f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape BEFORE slicing: (1693627, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X = X.iloc[:, :36]\n",
        "# print(\"X shape AFTER slicing:\", X.shape)\n"
      ],
      "metadata": {
        "id": "pqbuLebDrriA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    # HTTP floods\n",
        "    \"Goldeneye1\": \"HTTP_Flood\",\n",
        "    \"Goldeneye2\": \"HTTP_Flood\",\n",
        "    \"Torshammer1\": \"HTTP_Flood\",\n",
        "    \"Torshammer2\": \"HTTP_Flood\",\n",
        "\n",
        "    # Slow DoS\n",
        "    \"Slowloris1\": \"Slowrate_DoS\",\n",
        "    \"Slowloris2\": \"Slowrate_DoS\",\n",
        "\n",
        "    # UDP flood\n",
        "    \"UDPFlood1\": \"UDP_Flood\",\n",
        "    \"UDPFlood2\": \"UDP_Flood\",\n",
        "\n",
        "    # SYN flood\n",
        "    \"SYNFlood1\": \"SYN_Flood\",\n",
        "    \"SYNFlood2\": \"SYN_Flood\",\n",
        "\n",
        "    # ICMP flood\n",
        "    \"ICMPFlood1\": \"ICMP_Flood\",\n",
        "    \"ICMPFlood2\": \"ICMP_Flood\",\n",
        "\n",
        "    # Scans\n",
        "    \"UDPScan1\": \"UDP_Scan\",\n",
        "    \"UDPScan2\": \"UDP_Scan\",\n",
        "\n",
        "    \"SYNScan1\": \"SYN_Scan\",\n",
        "    \"SYNScan2\": \"SYN_Scan\",\n",
        "\n",
        "    \"TCPConnect1\": \"TCP_Connect_Scan\",\n",
        "    \"TCPConnect2\": \"TCP_Connect_Scan\",\n",
        "\n",
        "    # Benign (already correct)\n",
        "    \"Benign\": \"Benign\",\n",
        "\n",
        "    # SSH (DROP â€” not used)\n",
        "    \"SSH1\": None,\n",
        "    \"SSH2\": None\n",
        "}"
      ],
      "metadata": {
        "id": "kzsXlpylrs_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Label\"] = df[\"Label\"].map(label_map)\n",
        "\n",
        "# Remove rows mapped to None (SSH etc.)\n",
        "df = df.dropna(subset=[\"Label\"])"
      ],
      "metadata": {
        "id": "Aw_ldnCqrutv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(df[\"Label\"].unique()))\n",
        "print(\"Number of classes:\", df[\"Label\"].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BbXaBewsFin",
        "outputId": "2a8ee2ec-ab21-4aeb-863f-0ea444888fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Benign', 'HTTP_Flood', 'ICMP_Flood', 'SYN_Flood', 'SYN_Scan', 'Slowrate_DoS', 'TCP_Connect_Scan', 'UDP_Flood', 'UDP_Scan']\n",
            "Number of classes: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features & labels\n",
        "X = df.drop(columns=[\"Label\"])\n",
        "y = df[\"Label\"]\n",
        "\n",
        "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Convert to numeric\n",
        "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# Remove inf first\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Fill NaNs BEFORE QT\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "\n",
        "# EXACT 36 features (fixed, no filtering later)\n",
        "X = X.iloc[:, :36]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "y_onehot = tf.keras.utils.to_categorical(y_enc, 9)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y_enc\n",
        ")\n",
        "\n",
        "\n",
        "# Quantile transform (paper style)\n",
        "qt = QuantileTransformer(\n",
        "    n_quantiles=1000,\n",
        "    output_distribution=\"normal\",\n",
        "    random_state=42\n",
        ")\n",
        "X_train = qt.fit_transform(X_train)\n",
        "X_test  = qt.transform(X_test)\n",
        "\n",
        "X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_test  = np.nan_to_num(X_test,  nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "# Reshape\n",
        "X_train = X_train.reshape(-1, 36, 1)\n",
        "X_test  = X_test.reshape(-1, 36, 1)\n"
      ],
      "metadata": {
        "id": "rb9pgjsi23t1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b211c7-58ad-40e5-af1e-c46e16aed025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:1634: RuntimeWarning: All-NaN slice encountered\n",
            "  return fnb._ureduce(a,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NaNs in X:\", np.isnan(X_train).sum())\n",
        "print(\"Infs in X:\", np.isinf(X_test).sum())\n",
        "print(\"y unique sums:\", np.unique(y_train.sum(axis=1)))"
      ],
      "metadata": {
        "id": "AMllzHFE2970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0fc61da-b883-4f4d-aa8c-e30d7efda6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaNs in X: 0\n",
            "Infs in X: 0\n",
            "y unique sums: [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# import numpy as np\n",
        "\n",
        "# X = df.drop(columns=[\"Label\"])\n",
        "# y = df[\"Label\"]\n",
        "\n",
        "# le = LabelEncoder()\n",
        "# y_encoded = le.fit_transform(y)\n",
        "\n",
        "# NUM_CLASSES = len(np.unique(y_encoded))\n",
        "# y_onehot = to_categorical(y_encoded, NUM_CLASSES)\n",
        "\n",
        "# print(\"Final NUM_CLASSES:\", NUM_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t4Noi9HsHM4",
        "outputId": "4433cf7d-bf9b-45ef-c640-7207c38b07a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final NUM_CLASSES: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ALWAYS start from df\n",
        "# X = df.drop(columns=[\"Label\"])\n",
        "# y = df[\"Label\"]\n",
        "\n",
        "# # Force numeric\n",
        "# X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "# X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "# X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# print(\"X shape BEFORE slicing:\", X.shape)\n",
        "#  # MUST be > 36 columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgON5eMGsIeu",
        "outputId": "69ccfb80-6f32-42a2-d867-8ad2dff295ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape BEFORE slicing: (1690661, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Replace inf â†’ nan\n",
        "# X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# # Fill nan with column mean\n",
        "# X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# # Final check\n",
        "# print(\"NaNs:\", X.isna().sum().sum())\n",
        "# print(\"Infs:\", np.isinf(X.values).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_3j36eosJsO",
        "outputId": "11fcb897-063b-4083-a95a-2465eccaf7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaNs: 10143966\n",
            "Infs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # MUST be done on X BEFORE split & scaling\n",
        "# X = X.iloc[:, :36]\n",
        "# print(\"X shape after slicing:\", X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mqTVnApsLi3",
        "outputId": "38536432-649c-4934-f7f1-83650b28eeeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape after slicing: (1690661, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X,\n",
        "#     y_onehot,\n",
        "#     test_size=0.2,\n",
        "#     random_state=42,\n",
        "#     stratify=y_encoded\n",
        "# )"
      ],
      "metadata": {
        "id": "nz_wyESTsMl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# qt = QuantileTransformer(\n",
        "#     n_quantiles=1000,\n",
        "#     output_distribution=\"normal\",\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# X_train = qt.fit_transform(X_train)\n",
        "# X_test  = qt.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmFNtMhOsOW4",
        "outputId": "8bdca6c4-0918-4da1-b096-2832ced78075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:1634: RuntimeWarning: All-NaN slice encountered\n",
            "  return fnb._ureduce(a,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"X_train shape before reshape:\", X_train.shape)\n",
        "# print(\"X_test shape before reshape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_vysDkCsOsX",
        "outputId": "70267706-b489-45ad-e94c-789613613b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape before reshape: (1352528, 36)\n",
            "X_test shape before reshape: (338133, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = X_train.reshape(-1, 36, 1, 1)\n",
        "# X_test  = X_test.reshape(-1, 36, 1, 1)\n",
        "\n",
        "\n",
        "# print(\"Train shape:\", X_train.shape)\n",
        "# print(\"Test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0oApzfxsPtH",
        "outputId": "138d88d3-97d5-499f-d673-a006d80f3dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1352528, 36, 1, 1)\n",
            "Test shape: (338133, 36, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "# import numpy as np\n",
        "\n",
        "# class_weights = compute_class_weight(\n",
        "#     class_weight=\"balanced\",\n",
        "#     classes=np.unique(y_encoded),\n",
        "#     y=y_encoded\n",
        "# )\n",
        "\n",
        "# class_weights = dict(enumerate(class_weights))\n",
        "# print(class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XffN_htsQuP",
        "outputId": "f0294d35-4f7d-467d-c71a-f326726837b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: np.float64(0.39321053680628093), 1: np.float64(0.7302509785424706), 2: np.float64(5.739244820574447), 3: np.float64(3.1977941955301343), 4: np.float64(8.175975897554936), 5: np.float64(4.301509519411559), 6: np.float64(8.062976316517393), 7: np.float64(0.2491679717079431), 8: np.float64(9.231925605574121)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rM3fCz7QsTBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MOBILENET V1 MODEL**"
      ],
      "metadata": {
        "id": "REMTTkSbs6bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, DepthwiseConv2D,\n",
        "    BatchNormalization, ReLU,\n",
        "    GlobalAveragePooling2D, Dense, LayerNormalization\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "iarByJNGsTNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def depthwise_separable_conv(x, filters):\n",
        "    x = DepthwiseConv2D((3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters, (1,1), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "3Qwt0nfdsTlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def depthwise_separable_conv(x, filters):\n",
        "    x = DepthwiseConv2D((3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters, (1,1), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "AzU72TlmsUl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MobileNetV1_5G(input_shape=(36,1,1), num_classes=8):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial Conv\n",
        "    x = Conv2D(32, (3,3), padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # MobileNet blocks\n",
        "    x = depthwise_separable_conv(x, 64)\n",
        "    x = depthwise_separable_conv(x, 128)\n",
        "\n",
        "    # Global pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # ğŸ”‘ NUMERICAL STABILITY (THIS FIXES NaN LOSS)\n",
        "    x = LayerNormalization()(x)\n",
        "\n",
        "    # Classifier\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "rb36xxposVl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = MobileNetV1_5G(\n",
        "    input_shape=(36,1,1),\n",
        "    num_classes=9\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),   # LOWER LR = 1e-4  #better lr = 5e-5\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "eJKgZfJ2sWs3",
        "outputId": "500026e3-a54f-406e-c2e3-525fba94f20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚         \u001b[38;5;34m2,112\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_1              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚           \u001b[38;5;34m640\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚         \u001b[38;5;34m8,320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mLayerNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              â”‚         \u001b[38;5;34m1,161\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_1              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,161</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,409\u001b[0m (56.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,409</span> (56.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,769\u001b[0m (53.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,769</span> (53.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# X_train[np.isinf(X_train)] = np.nan\n",
        "# X_test[np.isinf(X_test)] = np.nan\n",
        "\n",
        "# X_train = np.nan_to_num(X_train)\n",
        "# X_test = np.nan_to_num(X_test)\n",
        "\n",
        "# print(\"NaNs:\", np.isnan(X_train).sum())\n",
        "# print(\"Infs:\", np.isinf(X_train).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN8ya42TsYJ3",
        "outputId": "d326910e-004a-405a-db02-2b0a009e76c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaNs: 0\n",
            "Infs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZMmoa16saAH",
        "outputId": "4f6faa3b-e23a-4981-c508-654ac2d8aa40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 5ms/step - accuracy: 0.6228 - loss: 0.8580 - val_accuracy: 0.6425 - val_loss: 0.7145\n",
            "Epoch 2/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 5ms/step - accuracy: 0.6523 - loss: 0.6620 - val_accuracy: 0.6415 - val_loss: 0.7472\n",
            "Epoch 3/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 5ms/step - accuracy: 0.6546 - loss: 0.6406 - val_accuracy: 0.6380 - val_loss: 0.6724\n",
            "Epoch 4/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 5ms/step - accuracy: 0.6569 - loss: 0.6291 - val_accuracy: 0.6662 - val_loss: 0.6396\n",
            "Epoch 5/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 5ms/step - accuracy: 0.6582 - loss: 0.6198 - val_accuracy: 0.6637 - val_loss: 0.7016\n",
            "Epoch 6/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 5ms/step - accuracy: 0.6597 - loss: 0.6125 - val_accuracy: 0.6506 - val_loss: 0.6852\n",
            "Epoch 7/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5ms/step - accuracy: 0.6602 - loss: 0.6118 - val_accuracy: 0.6397 - val_loss: 0.6884\n",
            "Epoch 8/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 5ms/step - accuracy: 0.6600 - loss: 0.6068 - val_accuracy: 0.6652 - val_loss: 0.7090\n",
            "Epoch 9/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 5ms/step - accuracy: 0.6615 - loss: 0.6047 - val_accuracy: 0.6647 - val_loss: 0.6986\n",
            "Epoch 10/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 5ms/step - accuracy: 0.6615 - loss: 0.6032 - val_accuracy: 0.6656 - val_loss: 0.6458\n",
            "Epoch 11/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 5ms/step - accuracy: 0.6615 - loss: 0.5976 - val_accuracy: 0.6620 - val_loss: 0.6524\n",
            "Epoch 12/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 5ms/step - accuracy: 0.6623 - loss: 0.5950 - val_accuracy: 0.6345 - val_loss: 0.7078\n",
            "Epoch 13/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.5933 - val_accuracy: 0.6687 - val_loss: 0.6752\n",
            "Epoch 14/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 5ms/step - accuracy: 0.6626 - loss: 0.5900 - val_accuracy: 0.6659 - val_loss: 0.6951\n",
            "Epoch 15/15\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.5905 - val_accuracy: 0.6659 - val_loss: 0.6800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79ee2f3e9d60>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZkuv50aruij",
        "outputId": "60dc1f3e-7860-42ef-8210-396e6a72e13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 5ms/step - accuracy: 0.7043 - loss: 0.6276 - val_accuracy: 0.7151 - val_loss: 0.5615\n",
            "Epoch 2/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.5631 - val_accuracy: 0.7164 - val_loss: 0.5950\n",
            "Epoch 3/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5ms/step - accuracy: 0.7142 - loss: 0.5519 - val_accuracy: 0.7094 - val_loss: 0.5787\n",
            "Epoch 4/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5ms/step - accuracy: 0.7141 - loss: 0.5474 - val_accuracy: 0.7158 - val_loss: 0.5399\n",
            "Epoch 5/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5ms/step - accuracy: 0.7149 - loss: 0.5438 - val_accuracy: 0.7164 - val_loss: 0.5351\n",
            "Epoch 6/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 5ms/step - accuracy: 0.7153 - loss: 0.5402 - val_accuracy: 0.7177 - val_loss: 0.5345\n",
            "Epoch 7/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 5ms/step - accuracy: 0.7154 - loss: 0.5387 - val_accuracy: 0.7171 - val_loss: 0.5374\n",
            "Epoch 8/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 5ms/step - accuracy: 0.7157 - loss: 0.5370 - val_accuracy: 0.7165 - val_loss: 0.5339\n",
            "Epoch 9/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 5ms/step - accuracy: 0.7154 - loss: 0.5362 - val_accuracy: 0.7117 - val_loss: 0.5359\n",
            "Epoch 10/10\n",
            "\u001b[1m21134/21134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 5ms/step - accuracy: 0.7155 - loss: 0.5342 - val_accuracy: 0.7181 - val_loss: 0.5293\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6eccdbd160>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OxYWh9Jsa9n",
        "outputId": "3c4af3f0-6c55-42ad-b150-ce9147474af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10567/10567\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.7185 - loss: 0.5291\n",
            "Test Accuracy: 0.7180872559547424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "labels, counts = np.unique(y_enc, return_counts=True)\n",
        "for l, c in zip(le.classes_, counts):\n",
        "    print(l, c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHzYzWbscF3",
        "outputId": "113f536e-1ebf-4a70-c7e3-a2c6462733fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benign 477737\n",
            "HTTP_Flood 257242\n",
            "ICMP_Flood 32731\n",
            "SYN_Flood 58744\n",
            "SYN_Scan 22976\n",
            "Slowrate_DoS 43671\n",
            "TCP_Connect_Scan 23298\n",
            "UDP_Flood 753914\n",
            "UDP_Scan 20348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVJ-7gYlsdPu",
        "outputId": "45777558-991a-46b2-f54c-73f5fa0f5068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10567/10567\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "          Benign       0.50      0.59      0.55     95548\n",
            "      HTTP_Flood       0.97      0.80      0.88     51448\n",
            "      ICMP_Flood       0.66      0.05      0.10      6546\n",
            "       SYN_Flood       0.91      0.18      0.30     11749\n",
            "        SYN_Scan       1.00      0.88      0.93      4595\n",
            "    Slowrate_DoS       0.90      0.30      0.45      8734\n",
            "TCP_Connect_Scan       0.95      0.87      0.91      4660\n",
            "       UDP_Flood       0.78      0.85      0.81    150783\n",
            "        UDP_Scan       1.00      0.77      0.87      4070\n",
            "\n",
            "        accuracy                           0.72    338133\n",
            "       macro avg       0.85      0.59      0.64    338133\n",
            "    weighted avg       0.74      0.72      0.71    338133\n",
            "\n"
          ]
        }
      ]
    }
  ]
}